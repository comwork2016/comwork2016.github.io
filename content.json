{"meta":{"title":"Liao's Blog","subtitle":"强迫症患者","description":null,"author":"huangyedi2012","url":"https://comwork2016.github.io"},"pages":[{"title":"关于","date":"2017-03-31T05:22:46.000Z","updated":"2017-04-01T11:56:30.619Z","comments":true,"path":"about/index.html","permalink":"https://comwork2016.github.io/about/index.html","excerpt":"","text":"本博客中的内容是本人在计算机专业学习中所作的记录，只是方便本人在以后有所遗忘时进行查阅。有部分文章是从网络中获取，如有侵权，请联系我。","raw":null,"content":null},{"title":"分类","date":"2017-03-31T05:54:13.000Z","updated":"2017-04-01T11:56:30.619Z","comments":true,"path":"categories/index.html","permalink":"https://comwork2016.github.io/categories/index.html","excerpt":"","text":"","raw":null,"content":null},{"title":"标签","date":"2017-03-31T05:54:06.000Z","updated":"2017-04-01T11:56:30.626Z","comments":true,"path":"tags/index.html","permalink":"https://comwork2016.github.io/tags/index.html","excerpt":"","text":"","raw":null,"content":null}],"posts":[{"title":"隐性语义索引（Latent Semantic Indexing）","slug":"隐性语义索引（Latent-Semantic-Indexing）","date":"2017-04-12T02:33:12.000Z","updated":"2017-04-13T11:34:28.082Z","comments":true,"path":"2017/04/12/隐性语义索引（Latent-Semantic-Indexing）/","link":"","permalink":"https://comwork2016.github.io/2017/04/12/隐性语义索引（Latent-Semantic-Indexing）/","excerpt":"隐性语义索引(LSI)采用线性代数中的奇异值分解方法，选取前几个比较大的奇异值所对应的特征向量将原矩阵映射到低维空间中，从而达到词矢量的目的。","text":"隐性语义索引(LSI)采用线性代数中的奇异值分解方法，选取前几个比较大的奇异值所对应的特征向量将原矩阵映射到低维空间中，从而达到词矢量的目的。 奇异矩阵分解SVD奇异矩阵分解SVD的内容见上文博客。 词项—文档矩阵及SVD词项-文档矩阵是一个由$M$个词项和$N$篇文档组成的$M×N$的权重矩阵$C$，矩阵的每行代表一个词项，每列代表一篇文档。然而，我们感兴趣的是$M×N$的词项—文档矩阵$C$，一般有$M\\neq N$。这个矩阵经过SVD分解之后的形势如下式所示： $$\\begin{equation}CC^T =UΣV^TVΣ^TU^T =UΣΣ^TU^T\\end{equation}$$ 那么左边的$CC^T$ 代表什么呢？它实际上是一个方阵，其每行和每列都对应$M$个词项中的一个。矩阵中的第$i$行、第$j$列的元素实际上是第$i$个词项与第$j$个词项基于文档共现次数的一个重合度计算指标（可以从矩阵的乘法中推断出来）。其精确的数学含义依赖于构建$C$所使用的词项权重方法。假定$C$是词项-文档出现矩阵，那么$CC^T$的第$i$行、第$j$列的元素是词项$i$和词项$j$共现的文档数目。 低秩逼近小特征值对于矩阵乘法的影响也小。因此，将这些小特征值替换成0将不会对最后的乘积有实质性影响，也就是说该乘积接近$C$。SVD可以用于解决矩阵低秩逼近问题，主要操作分为以下三步： 给定$C$，构造SVD分解有$C = UΣV^T$； 把$Σ$中对角线上$r-k$个最小奇异值置为0，从而得到$Σ_k$； 计算$C_k = UΣ_kV^T$作为$C$的逼近。 潜在语义索引LSI空间向量模型可以将查询和文档转换成同一空间下的向量，可以基于余弦相似度进行评分计算，能够对不同的词项赋予不同的权重，除了文档检索之外还可以推广到诸如聚类和分类等其他领域，等等。但是，向量空间表示方法没有能力处理自然语言中的两个经典问题：一义多词（synonymy）和一词多义（polysemy）问题。一个很自然的问题就是，能否利用词项的共现情况（比如，charge是和steed 还是electron在某篇文档中共现），来获得词项的隐性语义关联从而减轻这些问题的影响？ 即使对一个中等规模的文档集来说，词项-文档矩阵$C$也可能有成千上万个行和列，它的秩数目大概也是这个数量级。在LSI中，我们使用SVD分解来构造$C$的一个低秩逼近$C_k$，其中$k$远小于矩阵$C$原始的秩。实践时$k$的取值往往在几百以内。这样，我们就可以将词项—文档矩阵中每行和每列（分别对应每个词项和每篇文档）映射到一个$k$维空间，为$CC^T$和$C^TC$的$k$个主特征向量（对应$k$个最大的特征值）可以定义该空间。需要注意的是，不管$k$取值如何，矩阵$C_k$仍然是一个$M × N$的矩阵。矩阵$U$被称为SVD词项矩阵（SVD term matrix）,$V^T$被称为SVD文档矩阵（SVD document matrix）。 举例考虑如下词项—文档矩阵 C = $d_1$ $d_2$ $d_3$ $d_4$ $d_5$ $d_6$ ship 1 0 1 0 0 0 boat 0 1 0 0 0 0 ocean 1 1 0 0 0 0 voyage 1 0 0 1 1 0 trip 0 0 0 1 0 1 利用SVD分解，可以将其分解生成三个矩阵的乘积。 计算$CC^T$的值为 $$\\begin{eqnarray}CC^T=\\begin{pmatrix}1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\\\0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 \\\\0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1\\end{pmatrix}\\begin{pmatrix}1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 \\\\0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\\\1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\\\0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\0 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\end{pmatrix}=\\begin{pmatrix}2 &amp; 0 &amp; 1 &amp; 1 &amp; 0 \\\\0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\\\1 &amp; 1 &amp; 2 &amp; 1 &amp; 0 \\\\1 &amp; 0 &amp; 1 &amp; 3 &amp; 1 \\\\0 &amp; 0 &amp; 0 &amp; 1 &amp; 2\\end{pmatrix}\\end{eqnarray}$$ $CC^T$对应的特征值和特征向量为： $$\\begin{equation}\\lambda_1=4.68,p_1=\\begin{pmatrix} 0.44 &amp; 0.13 &amp; 0.48 &amp; 0.70 &amp; 0.26 \\end{pmatrix}^T\\\\\\lambda_2=2.54,p_2=\\begin{pmatrix} 0.30 &amp; 0.33 &amp; 0.51 &amp; -0.35 &amp; -0.65 \\end{pmatrix}^T\\\\\\lambda_3=1.63,p_3=\\begin{pmatrix} 0.57 &amp; -0.59 &amp; -0.37 &amp; 0.15 &amp; -0.41 \\end{pmatrix}^T\\\\\\lambda_4=1,p_4=\\begin{pmatrix} 0.58 &amp; -0.00 &amp; -0.00 &amp; -0.58 &amp; 0.58 \\end{pmatrix}^T\\\\\\lambda_5=0.16,p_5=\\begin{pmatrix} -0.25 &amp; -0.73 &amp; 0.61 &amp; -0.16 &amp; 0.09 \\end{pmatrix}^T\\end{equation}$$ 计算$C^TC$的值为$$\\begin{eqnarray}C^TC=\\begin{pmatrix}1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 \\\\0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\\\1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\\\0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\0 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\end{pmatrix}\\begin{pmatrix}1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\\\0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 \\\\0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1\\end{pmatrix}=\\begin{pmatrix}3 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 0 \\\\1 &amp; 2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\\\1 &amp; 0 &amp; 0 &amp; 2 &amp; 1 &amp; 1 \\\\1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 \\\\0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1\\end{pmatrix}\\end{eqnarray}$$ $C^TC$对应的特征值和特征向量为： $$\\begin{equation}\\lambda_1=4.68,p_1=\\begin{pmatrix} -0.75 &amp; -0.28 &amp; -0.20 &amp; -0.45 &amp; -0.33 &amp; -0.12 \\end{pmatrix}^T\\\\\\lambda_2=2.54,p_2=\\begin{pmatrix} -0.29 &amp; -0.53 &amp; -0.19 &amp; 0.63 &amp; 0.22 &amp; 0.41 \\end{pmatrix}^T\\\\\\lambda_3=1.63,p_3=\\begin{pmatrix} -0.28 &amp; 0.75 &amp; -0.45 &amp; 0.20 &amp; -0.12 &amp; 0.33 \\end{pmatrix}^T\\\\\\lambda_4=1,p_4=\\begin{pmatrix} 0.00 &amp; -0.00 &amp; 0.58 &amp; -0.00 &amp; -0.58 &amp; 0.58 \\end{pmatrix}^T\\\\\\lambda_5=0.16,p_5=\\begin{pmatrix} 0.53 &amp; -0.29 &amp; -0.63 &amp; -0.19 &amp; -0.41 &amp; 0.22 \\end{pmatrix}^T\\\\\\lambda_6=0.16,p_6=\\begin{pmatrix} 0.00 &amp; -0.00 &amp; -0.00 &amp; -0.58 &amp; 0.58 &amp; 0.58 \\end{pmatrix}^T\\end{equation}$$ 则根据以上SVD分解有： $$\\begin{eqnarray}C&amp;=&amp;UΣV^T=\\begin{pmatrix}1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\\\0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 \\\\0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1\\end{pmatrix}\\\\&amp;=&amp;\\begin{pmatrix}0.44 &amp; 0.30 &amp; 0.57 &amp; 0.58 &amp; -0.25 \\\\0.13 &amp; 0.33 &amp; -0.59 &amp; -0.00 &amp; -0.73 \\\\0.48 &amp; 0.51 &amp; -0.37 &amp; -0.00 &amp; 0.61 \\\\0.70 &amp; -0.35 &amp; 0.15 &amp; -0.58 &amp; -0.16 \\\\0.26 &amp; -0.65 &amp; -0.41 &amp; 0.58 &amp; 0.09\\end{pmatrix}\\\\&amp;\\times&amp;\\begin{pmatrix}2.16 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\0 &amp; 1.59 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\0 &amp; 0 &amp; 1.28 &amp; 0 &amp; 0 &amp; 0\\\\0 &amp; 0 &amp; 0 &amp; 1.00 &amp; 0 &amp; 0\\\\0 &amp; 0 &amp; 0 &amp; 0 &amp; 0.39 &amp; 0\\end{pmatrix}\\\\&amp;\\times&amp;\\begin{pmatrix}-0.75 &amp; -0.29 &amp; -0.28 &amp; 0.00 &amp; 0.53 &amp; 0.00 \\\\-0.28 &amp; -0.53 &amp; 0.75 &amp; -0.00 &amp; -0.29 &amp; -0.00 \\\\-0.20 &amp; -0.19 &amp; -0.45 &amp; 0.58 &amp; -0.63 &amp; -0.00 \\\\-0.45 &amp; 0.63 &amp; 0.20 &amp; -0.00 &amp; -0.19 &amp; -0.58 \\\\-0.33 &amp; 0.22 &amp; -0.12 &amp; -0.58 &amp; -0.41 &amp; 0.58 \\\\-0.12 &amp; 0.41 &amp; 0.33 &amp; 0.58 &amp; 0.22 &amp; 0.58\\end{pmatrix} ^T\\\\&amp;=&amp;\\begin{pmatrix}-1.10 &amp; 0.06 &amp; -0.21 &amp; 0.04 &amp; -0.59 &amp; 0.62 \\\\-0.30 &amp; -0.84 &amp; 0.36 &amp; 0.11 &amp; 0.23 &amp; -0.13 \\\\-0.74 &amp; -1.14 &amp; -0.30 &amp; -0.09 &amp; -0.20 &amp; 0.11 \\\\-1.07 &amp; 0.04 &amp; -0.59 &amp; -0.98 &amp; -0.28 &amp; -0.69 \\\\0.04 &amp; -0.02 &amp; 0.62 &amp; -1.01 &amp; -0.69 &amp; -0.32\\end{pmatrix}\\end{eqnarray}$$ 取$k=2$，此时左奇异向量为 $$\\begin{eqnarray}U_{5\\times 2}=\\begin{pmatrix}0.44 &amp; 0.30 \\\\0.13 &amp; 0.33\\\\0.48 &amp; 0.51\\\\0.70 &amp; -0.35\\\\0.26 &amp; -0.65\\end{pmatrix}\\end{eqnarray}$$ 因为$0.44 \\gt 0.30$，这表示第一个词与第一维空间更接近，依次类推。 右奇异矩阵为： $$\\begin{eqnarray}U^T_{2\\times 6}=\\begin{pmatrix}-0.75 &amp; -0.28 &amp; -0.20 &amp; -0.45 &amp; -0.33 &amp; -0.12 \\\\-0.29 &amp; -0.53 &amp; -0.19 &amp; 0.63 &amp; 0.22 &amp; 0.41\\end{pmatrix}\\end{eqnarray}$$ 第一列表示文章$d_1$与第一维空间更接近，在些基础上可利用余弦相似度对两篇文档在低维空间上进行相似度计算。 中间矩阵为： $$\\begin{eqnarray}\\Sigma = \\begin{pmatrix}2.16 &amp; 0.00 \\\\0.00 &amp; 1.59\\end{pmatrix}\\end{eqnarray}$$ 表示的是词和文章的相关关系。 参考文献 奇异值分解 SVD矩阵分解及隐性语义索引《数学之美》拾遗——潜在语义索引(LSI)","raw":null,"content":null,"categories":[{"name":"ML","slug":"ML","permalink":"https://comwork2016.github.io/categories/ML/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://comwork2016.github.io/tags/NLP/"},{"name":"LSI","slug":"LSI","permalink":"https://comwork2016.github.io/tags/LSI/"}]},{"title":"奇异值分解 SVD","slug":"奇异值分解-SVD","date":"2017-04-12T00:56:22.000Z","updated":"2017-04-13T08:45:57.858Z","comments":true,"path":"2017/04/12/奇异值分解-SVD/","link":"","permalink":"https://comwork2016.github.io/2017/04/12/奇异值分解-SVD/","excerpt":"奇异值分解(Singular Value Decomposition，以下简称SVD)是在机器学习领域广泛应用的算法，它不光可以用于降维算法中的特征分解，还可以用于推荐系统，以及自然语言处理等领域。是很多机器学习算法的基石。","text":"奇异值分解(Singular Value Decomposition，以下简称SVD)是在机器学习领域广泛应用的算法，它不光可以用于降维算法中的特征分解，还可以用于推荐系统，以及自然语言处理等领域。是很多机器学习算法的基石。 线性变换的几何解释首先，我们来看一个只有两行两列的简单矩阵。 $$\\begin{equation}\\mathbf{M}=\\begin{bmatrix} 2 &amp; 1 \\\\ 1 &amp; 2\\end{bmatrix}\\end{equation}$$ 从几何的角度，矩阵可以描述为一个变换：用矩阵乘法将平面上的点$(x,y)$ 变换成另外一个点 $(2x+y,x+2y)$ : $$\\begin{equation} \\begin{bmatrix} 2 &amp; 1 \\\\ 1 &amp; 2 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} 2x+y \\\\ x+2y \\end{bmatrix} \\nonumber\\end{equation}$$ 这种变换的效果如下： 不过这张图貌似也并没有能够简洁、清晰的描述出上述矩阵变换的几何效果。然而，如果我们把网格旋转45度，再观察一下。 我们看到现在这个新的网格在某一方向上被拉伸了3倍。 如果我们有一个2*2的对称矩阵，可以证明，我们总是可以通过在平面上旋转网格，使得矩阵变换的效果恰好是在两个垂直的方向上对网格的拉伸或镜面反射。 即给定一个对称矩阵 $M$ ，我们可以找到一组正交向量 $v_i$ 使得 $Mv_i$ 等于 $v_i$ 和标量的乘积；那就是 $$\\begin{equation} Mv_i = \\lambda_i v_i\\end{equation}$$ 这里$\\lambda_i$ 是标量。从几何意义上讲，这意味着当$v_i$ 乘上矩阵 $M$ 时被简单地拉伸或者反射了。因为这个性质，我们称 $v_i$ 是 $M$ 的特征向量；标量 $\\lambda_i$ 被称为特征值。一个可以被证明的重要的事实是：对称矩阵不同的特征值对应的特征向量是正交的。如果我们把对称矩阵的特征向量和网格对齐，那么矩阵对网格的拉伸或反射的方式，与矩阵对特征向量的拉伸或反射的方式，两者是完全一致的。 奇异值分解2*2矩阵奇异值分解的几何实质是：对于任意2*2矩阵，总能找到某个正交网格到另一个正交网格的转换与矩阵变换相对应。 用向量解释这个现象：选择适当的正交的单位向量 $v_1$ 和$v_2$ ，向量 $Mv_i$ 和 $Mv_2$ 也是正交的。 用 $u_1$ 和 $u_2$ 来表示 $Mv_1$ 和 $Mv_2$ 方向上的单位向量。 $Mv_1$ 和 $Mv_2$ 的长度用$\\sigma_1$ 和 $\\sigma_2$ 来表示——量化了网格在特定方向上被拉伸的效果。 $\\sigma_1$ 和 $\\sigma_2$ 被称为 $M$ 的奇异值。 由此，我们有 $$\\begin{equation} Mv_1 = \\sigma_1 u_1\\\\\\ Mv_2 = \\sigma_2 u_2\\end{equation}$$ 因为向量 $v_1$ 和 $v_2$ 是正交的单位向量，我们有 $$\\begin{equation} x = (v_1 \\cdot x)v_1 + (v_2 \\cdot x)v_2\\end{equation}$$ $v_1 \\cdot x$ 为单位向量与向量的内积，表示向量在该单位向量方向上的投影。 则有： $$\\begin{eqnarray} Mx &amp;=&amp; (v_1 \\cdot x)Mv_1 + (v_2 \\cdot x)Mv_2 \\\\ &amp;=&amp; (v_1 \\cdot x)\\sigma_1 u_1 + (v_2 \\cdot x)\\sigma_2 u_2\\end{eqnarray}$$ 注意点积（标量）可以用向量的转置来计算: $$\\begin{equation} v \\cdot x = v^T x\\end{equation}$$ 又有： $$\\begin{equation} Mx = u_1\\sigma_1 v_1^T x + u_2\\sigma_2 v_2^T x \\\\ M = u_1\\sigma_1 v_1^T + u_2\\sigma_2 v_2^T\\end{equation}$$ 即有：$$\\begin{eqnarray} M &amp;=&amp; \\left[\\begin{matrix} u_1 &amp; u_2 \\end{matrix}\\right] \\left[\\begin{matrix} \\sigma_1 &amp; \\\\ &amp;\\sigma_2 \\end{matrix}\\right] \\left[\\begin{matrix} v_1 &amp; v_2 \\end{matrix}\\right]^T \\\\ &amp;=&amp; \\left[\\begin{matrix} \\sigma_1u_1 &amp; \\sigma_2u_2 \\end{matrix}\\right] \\left[\\begin{matrix} v_1^T \\\\ v_2^T \\end{matrix}\\right] \\\\ &amp;=&amp; u_1\\sigma_1 v_1^T + u_2\\sigma_2 v_2^T\\end{eqnarray}$$ 将上式写成矩阵相乘的形式有： $$\\begin{equation} M = UΣV^T\\end{equation}$$ 这里 $U$ 是列向量 $u_1$ 和 $u_2$ 组成的矩阵，$Σ$ 是非零项为 $\\sigma_1$ 和 $\\sigma_2$ 的对角矩阵， $V$ 是列向量 $v_1$ 和 $v_2$ 组成的矩阵。 则有： $$\\begin{equation} MM^T=U(ΣΣ^T)U^T \\\\ M^T M = V(Σ^T Σ)V^T\\end{equation}$$ 关系式的右边描述了关系式左边的特征值分解。于是： $U$ 的列向量（左奇异向量）是 $MM^T$ 的特征向量。 $V$ 的列向量（右奇异向量）是 $M^T M$ 的特征向量。 $Σ$ 的非零对角元（非零奇异值）是 $MM^T$ 或者 $M^T M$ 的非零特征值的平方根。 上面描述了怎样将矩阵 $M$ 分解成三个矩阵的乘积： $V$ 描述了原始空间中的正交基， $U$ 描述了相关空间的正交基， $Σ$ 描述了 $V$ 中的向量变成 $U$ 中的向量时被拉伸的倍数。 举例SVD分解对以下矩阵进行SVD分解： $$\\begin{equation}C=\\begin{pmatrix}1 &amp; -1 \\\\0 &amp; 1\\\\1 &amp; 0\\\\-1 &amp; 1\\end{pmatrix}\\end{equation}$$ 计算$CC^T$矩阵的值如下： $$\\begin{equation}CC^T=\\begin{pmatrix}1 &amp; -1 \\\\0 &amp; 1\\\\1 &amp; 0\\\\-1 &amp; 1\\end{pmatrix}\\begin{pmatrix}1 &amp; 0 &amp; 1 &amp; -1\\\\-1 &amp; 1 &amp; 0 &amp; 1\\end{pmatrix}=\\begin{pmatrix}2 &amp; -1 &amp; 1 &amp; -2\\\\-1 &amp; 1 &amp; 0 &amp; 1\\\\1 &amp; 0 &amp; 1 &amp; -1\\\\-2 &amp; 1 &amp; -1 &amp; 2\\\\\\end{pmatrix} \\\\\\end{equation}$$ 对以上结果求解特征值和特征向量为： $$\\begin{equation}\\lambda_1 = 5,p_1=\\begin{pmatrix} -0.63 &amp; 0.32 &amp; -0.32 &amp; 0.63 \\end{pmatrix}^T\\\\\\lambda_2 = 1,p_2=\\begin{pmatrix} -0.00 &amp; -0.71 &amp; -0.71 &amp; 0.00 \\end{pmatrix}^T\\\\\\lambda_3 = 0,p_3=\\begin{pmatrix} -0.77 &amp; -0.26 &amp; 0.26 &amp; -0.52 \\end{pmatrix}^T\\\\\\lambda_4 = 0,p_4=\\begin{pmatrix} 0.02 &amp; -0.57 &amp; 0.57 &amp; 0.59 \\end{pmatrix}^T\\end{equation}$$ 计算$C^TC$矩阵的值如下： $$\\begin{equation}C^TC=\\begin{pmatrix}1 &amp; 0 &amp; 1 &amp; -1\\\\-1 &amp; 1 &amp; 0 &amp; 1\\end{pmatrix}\\begin{pmatrix}1 &amp; -1 \\\\0 &amp; 1\\\\1 &amp; 0\\\\-1 &amp; 1\\end{pmatrix}=\\begin{pmatrix}3 &amp; -2\\\\-2 &amp; 3\\end{pmatrix}\\end{equation}$$ 对以上结果求解特征值和特征向量为： $$\\begin{equation}\\lambda_1 = 5,p_1=\\begin{pmatrix} 0.71 &amp; -0.71 \\end{pmatrix}^T\\\\\\lambda_2 = 1,p_2=\\begin{pmatrix} 0.71 &amp; 0.71 \\end{pmatrix}^T\\end{equation}$$ 即，矩阵$C$分解之后有$$\\begin{equation}U=\\begin{pmatrix}-0.63 &amp; 0.00 \\\\0.32 &amp; -0.71 \\\\-0.32 &amp; -0.71 \\\\0.63 &amp; -0.00\\end{pmatrix}\\\\\\sqrt{S}=\\begin{pmatrix}2.236 &amp; 0\\\\0 &amp; 1\\end{pmatrix}\\\\V=\\begin{pmatrix}0.7071 &amp; 0.7071\\\\-0.7071 &amp; 0.7071\\end{pmatrix}\\end{equation}$$ 则有：$$\\begin{equation}C=U\\sqrt{S}V^T=\\begin{pmatrix}-0.63 &amp; 0.00 \\\\0.32 &amp; -0.71 \\\\-0.32 &amp; -0.71 \\\\0.63 &amp; -0.00\\end{pmatrix}\\begin{pmatrix}2.236 &amp; 0\\\\0 &amp; 1\\end{pmatrix}\\begin{pmatrix}0.7071 &amp; 0.7071\\\\-0.7071 &amp; 0.7071\\end{pmatrix}^T=\\begin{pmatrix}-1.00 &amp; 1.00 \\\\0.00 &amp; -1.00 \\\\-1.00 &amp; -0.00 \\\\1.00 &amp; -1.00\\end{pmatrix}\\end{equation}$$ 以上分解之后的矩阵的符号相反不影响。 数据压缩奇异值分解可以高效的表示数据。例如，假设我们想传送下列图片，包含15*25个黑色或者白色的像素阵列。 因为在图像中只有三种类型的列（如下），它可以以更紧凑的形式被表示。 我们用15*25的矩阵来表示这个图像，其中每个元素非0即1，0表示黑色像素，1表示白色像素。如下所示，共有375个元素。 如果对M进行奇异值分解的话，我们只会得到三个非零的奇异值。 $$\\begin{equation} \\sigma_1 = 14.72 \\\\ \\sigma_2 = 5.22 \\\\ \\sigma_3 = 3.31 \\\\\\end{equation}$$ 因此，矩阵可以如下表示 $$\\begin{equation} M = u_1\\sigma_1 v_1^T + u_2\\sigma_2 v_2^T + u_3\\sigma_3 v_3^T\\end{equation}$$ 我们有三个包含15个元素的向量 $v_i$ ，三个包含25个元素的向量 $u_i$ ，以及三个奇异值 $\\sigma_i$ 。这意味着我们可以只用123个数字就能表示这个矩阵而不是出现在矩阵中的375个元素。在这种方式下，我们看到在矩阵中有3个线性独立的列，也就是说矩阵的秩是3。 参考文献 奇异值分解（We Recommend a Singular Value Decomposition）","raw":null,"content":null,"categories":[{"name":"ML","slug":"ML","permalink":"https://comwork2016.github.io/categories/ML/"}],"tags":[{"name":"math","slug":"math","permalink":"https://comwork2016.github.io/tags/math/"},{"name":"ML","slug":"ML","permalink":"https://comwork2016.github.io/tags/ML/"},{"name":"SVD","slug":"SVD","permalink":"https://comwork2016.github.io/tags/SVD/"}]},{"title":"Hadoop 2.7.3 安装","slug":"Hadoop-2-7-3-安装","date":"2017-04-10T12:10:37.000Z","updated":"2017-04-11T03:26:41.712Z","comments":true,"path":"2017/04/10/Hadoop-2-7-3-安装/","link":"","permalink":"https://comwork2016.github.io/2017/04/10/Hadoop-2-7-3-安装/","excerpt":"在此记录hadoop 2.7.3版本的安装过程以及基本配置过程。","text":"在此记录hadoop 2.7.3版本的安装过程以及基本配置过程。 安装环境 jdk1.8 hadoop 2.7.3 CentOS release 6.7 (Final) * 3 hostname ip master 172.168.170.84 slave1 172.168.170.88 slave2 172.168.170.89 必需软件 JDK安装(下载地址) ssh安装 hadoop中使用ssh来实现cluster中各个node的登陆认证，同时需要进行ssh免密登陆。 1sudo apt-get install ssh rsync安装 Ubuntu 12.10已经自带rsync。 1sudo apt-get install rsync hadoop下载 从官方mirrors下载对应版本的hadoop。 安装Hadoop 创建hadoop用户组以及用户 12sudo addgroup hadoopsudo adduser --ingroup hadoop hadoop 重新用hadoop用户登陆到Linux中。 将hadoop解压到目录/home/hadoop/local/opt中 配置hadoop环境变量 12345678910export JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdk.x86_64/export PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport HADOOP_HOME=$HOME/local/opt/hadoop-2.7.3export HADOOP_HDFS_HOME=$HADOOP_HOMEexport HADOOP_MAPRED_HOME=$HADOOP_HOMEexport HADOOP_YARN_HOME=$HADOOP_HOMEexport HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoopexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 进入hadoop-2.7.3/etc/hadoop文件夹修改core-site.xml文件 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;io.file.buffer.size&lt;/name&gt; &lt;value&gt;131072&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/local/var/hadoop/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改hdfs-site.xml文件 123456789101112131415161718192021222324&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;master:9001&lt;/value&gt; &lt;description&gt;# 通过web界面来查看HDFS状态 &lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/home/hadoop/local/var/hadoop/hdfs/namenode&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/home/hadoop/local/var/hadoop/hdfs/datanode&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;description&gt;# 每个Block有1个备份&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改mapred-site.xml 这个是mapreduce任务的配置，由于hadoop2.x使用了yarn框架，所以要实现分布式部署，必须在mapreduce.framework.name属性下配置为yarn。mapred.map.tasks和mapred.reduce.tasks分别为map和reduce的任务数。 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;master:10020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;master:19888&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改yarn-site.xml 1234567891011121314151617181920212223242526272829303132333435&lt;configuration&gt; &lt;!-- Site specific YARN configuration properties --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;master:8032&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;master:8030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;master:8031&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &lt;value&gt;master:8033&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;master:8088&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt; &lt;value&gt;8192&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改slaves文件 12slave1slave2 修改hosts文件，命名各个节点的名称。 1234127.0.0.1 localhost172.168.170.84 master172.168.170.88 slave1172.168.170.89 slave2 节点之间ssh免密登陆在master节点中生成密钥，并添加到.ssh/authorized_keys文件中。 12ssh-keygen -t rsacat id_rsa.pub&gt;&gt; authorized_keys 将master中的/etc/hosts文件和.ssh/authorized_keys文件发送到slave1和slave2文件中。 123scp /etc/hosts hadoop@slave1:/etc/hostsscp /home/hadoop/.ssh/authorized_keys hadoop@slave1:/home/hadoop/.ssh/authorized_keysscp /home/hadoop/.ssh/authorized_keys hadoop@slave2:/home/hadoop/.ssh/authorized_keys 完成之后可以利用以下语句测试免密登陆。 12ssh slave1ssh slave2 将hadoop-2.7.3文件拷贝至slave1和slave2 12scp -r /home/hadoop/local/opt/hadoop-2.7.3 hadoop@slave1:/home/hadoop/local/opt/scp -r /home/hadoop/local/opt/hadoop-2.7.3 hadoop@slave2:/home/hadoop/local/opt/ 启动Hadoop 在master节点使用hadoop用户初始化NameNode 123hdfs namenode –format#执行后控制台输出，看到 Exiting with status 0 表示格式化成功。#如有错误，先删除var目录下的临时文件，然后重新运行该命令 启动hadoop 1234#启动hdfsstart-dfs.sh#启动yarn分布式计算框架start-yarn.sh 用jps命令查看hadoop集群运行情况 master节点 12345JpsNameNodeResourceManagerSecondaryNameNodeJobHistoryServer slave节点 123JpsDataNodeNodeManager 通过以下网址查看集群状态 12http://172.168.170.84:50070http://172.168.170.84:8088","raw":null,"content":null,"categories":[{"name":"hadoop","slug":"hadoop","permalink":"https://comwork2016.github.io/categories/hadoop/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://comwork2016.github.io/tags/hadoop/"}]},{"title":"最大公约数（辗转相除法）","slug":"最大公约数（辗转相除法）","date":"2017-04-09T08:06:44.000Z","updated":"2017-04-09T08:33:04.463Z","comments":true,"path":"2017/04/09/最大公约数（辗转相除法）/","link":"","permalink":"https://comwork2016.github.io/2017/04/09/最大公约数（辗转相除法）/","excerpt":"辗转相除法，又称欧几里得算法，是求最大公约数(Greatest Common Divisor)的算法。","text":"辗转相除法，又称欧几里得算法，是求最大公约数(Greatest Common Divisor)的算法。 算法描述设两数为$a$、$b$ $(a&gt;b)$，求$a$和$b$最大公约数$gcd(a，b)$的步骤如下： 用$b$除$a$，得$a÷b=q……r(0\\leq r)$。 若$r=0$，则$gcd(a,b)=b$；结束。 若$r≠0$，取$a=b,b=r$，执行第1步。 原理证明设两数为$a$、$b$ $(b\\leq a)$，用$gcd(a,b)$表示$a$，$b$的最大公约数，$r=a\\ mod\\ b $为$a$除以$b$以后的余数，$k$为$a$除以$b$的商，即$a÷b=k…….r$。 辗转相除法即是要证明$gcd(a,b)=gcd(b,r)$。 令$c=gcd(a,b)$，则设$a=mc$，$b=nc$ 则$r =a-kb=mc-knc=(m-kn)c$ 即$c$也是$r$的因数 可以断定$m-kn$与$n$互素【否则，可设$m-kn=xd$，$n=yd$，$(d&gt;1)$，则$m=kn+xd=kyd+xd=(ky+x)d$，则$a=mc=(ky+x)dc$，$b=nc=ycd$，故$a$与$b$最大公约数成为$cd$，而非$c$，与前面结论矛盾】 从而可知$gcd(b,r)=c$，继而$gcd(a,b)=gcd(b,r)$。 算法实现(c++)递归方式：1234567int gcd(int a,int b)&#123; if(b == 0) return b; else return gcd(b, a % b)&#125; 迭代方式：12345678910int gcd(int a, int b)&#123; while(b != 0) &#123; int r = a % b; a = b; b = r; &#125; return a;&#125;","raw":null,"content":null,"categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://comwork2016.github.io/categories/algorithm/"}],"tags":[{"name":"math","slug":"math","permalink":"https://comwork2016.github.io/tags/math/"},{"name":"gcd","slug":"gcd","permalink":"https://comwork2016.github.io/tags/gcd/"}]},{"title":"Logistic Regression","slug":"Logistic-Regression","date":"2017-04-01T01:12:45.000Z","updated":"2017-04-01T13:45:52.190Z","comments":true,"path":"2017/04/01/Logistic-Regression/","link":"","permalink":"https://comwork2016.github.io/2017/04/01/Logistic-Regression/","excerpt":"本文主要参考Andrew Ng老师的Machine Learning公开课，并用《机器学习实战》中的源码实现。","text":"本文主要参考Andrew Ng老师的Machine Learning公开课，并用《机器学习实战》中的源码实现。 Logistic Regression基本原理Logistic分布Logistic Distribution的分布函数和密度函数如下： $$\\begin{equation}F(x) = P(X \\leqslant x) = \\frac{1}{1+e^{-(x-\\mu)/\\gamma}}\\end{equation}$$ $$\\begin{equation}f(x)=F’(x) = \\frac{e^{-(x-\\mu)/\\gamma}} { \\gamma (1+e^{-(x-\\mu)/\\gamma})^2 }\\end{equation}$$ 上式中$ \\mu $是位置参数，$ \\gamma &gt; 0 $是形状参数。下图是不同参数对logistic分布的影响，从图中可以看到可以看到 $ \\mu $ 影响的是中心对称点的位置，$ \\gamma $越小中心点附近增长的速度越快。而常常在深度学习中用到的非线性变换$ sigmoid $函数是逻辑斯蒂分布的$ \\gamma=1,\\mu=0 $的特殊形式。 二项Logistic Regression模型 逻辑回归是为了解决分类问题，根据一些已知的训练集训练好模型，再对新的数据进行预测属于哪个类。对于上图中的数据，逻辑回归的目标是找到一个有足够好区分度的决策边界，从而能够将两类很好的分开。 分离边界的维数与空间的维数相关。如果是二维平面，分离边界就是一条线（一维）。如果是三维空间，分离边界就是一个空间中的面（二维）。如果是一维直线，分离边界就是直线上的某一点。 假设输入的特征向量为$ x \\in R^n $，$ Y $取值为$ 0，1 $。对于二维的空间，决策边界可以表示为$ w_1x_1+w_2x_2+b=0 $，假如存在一个例子使得$ h_w(x)=w_1x_1+w_2x_2+b&gt;0 $，那么可以判断它类别为$ 1 $，这个过程实际上是感知机，即只通过决策函数的符号来判断属于哪一类。而逻辑回归需要再进一步，它要找到分类概率$ P(Y=1)$与输入向量$ x $的直接关系，然后通过比较概率值来判断类别，而刚好上文中的logistic function能满足这样的要求，它令决策函数的输出值$ w^Tx+b = log \\frac{P(Y=1|x)}{1−P(Y=1|x)} $，求解这个式子得到了输入向量$ x $下导致产生两类的概率为： $$\\begin{equation}P(Y=1|x)=\\frac{e^{w\\cdot x+b}}{1+e^{w\\cdot x+b}}\\label{eq:logistic1}\\end{equation}$$ $$\\begin{equation}P(Y=0|x)=\\frac{1}{1+e^{w\\cdot x+b}}\\end{equation}$$ 其中$ w $称为权重，$ b $称为偏置，其中的$ w⋅x+b $看成对$ x $的线性函数，有时候为了书写方便，会将$ b $写入$ w $，即 $ w=(b,w_1,…,w_n) $ ，并取$ x=(1,x_1,…,x_n) $。然后对比上面两个概率值，概率值大的就是$ x $对应的类。 又已知一个事件发生的几率odds是指该事件发生与不发生的概率比值，二分类情况下即$ \\frac{P(Y=1|x)}{P(Y=0|x)}=\\frac{P(Y=1|x)}{1−P(Y=1|x)} $。取odds的对数就是上面提到的logistic function，$ logistic(P(Y=1|x))=log\\frac{P(Y=1|x)}{1−P(Y=1|x)}=w⋅x $。从而可以得到一种对逻辑回归的定义，输出$ Y=1 $的对数几率是由输入$ x $的线性函数表示的模型，即逻辑斯蒂回归模型(李航.《统计机器学习》)。而直接考察公式$\\eqref{eq:logistic1}$可以得到另一种对逻辑回归的定义，线性函数的值越接近正无穷，概率值就越接近1；线性值越接近负无穷，概率值越接近0，这样的模型是逻辑斯蒂回归模型(李航.《统计机器学习》)。因此逻辑回归的思路是，先拟合决策边界(这里的决策边界不局限于线性，还可以是多项式)，再建立这个边界与分类的概率联系，从而得到了二分类情况下的概率。 有了上面的分类概率，就可以建立似然函数，通过极大似然估计法来确定模型的参数。设$ P(Y=1|x)=h_w(x) $，似然函数为$ \\prod [h_w(x^{(i)})]^{y^{(i)}}[1-h_w(x^{(i)})]^{(1-y^{(i)})} $，对数似然函数为 $$\\begin{eqnarray}L(w) &amp; = &amp; \\sum_{i=1}^{N}\\log P(y^{(i)}|x^{(i)};w) \\\\&amp; = &amp; \\sum_{i=1}^{N}[y^{(i)}\\log h_w(x^{(i)})+(1-y^{(i)})\\log(1-h_w(x^{(i)}))]\\end{eqnarray}$$ 优化方法优化的主要目标是找到一个方向，参数朝这个方向移动之后使得似然函数的值能够减小，这个方向往往由一阶偏导或者二阶偏导各种组合求得。逻辑回归的损失函数是 $$\\begin{eqnarray}min J(w) &amp;=&amp; \\min \\frac{1}{m} \\sum_{j=1}^{m}Cost(h_w(x^{(i)}),y^{(i)}) \\\\&amp;=&amp; \\min {-\\frac{1}{m}[\\sum_{i=1}^{m}y^{(i)}\\log h_w(x^{(i)})+(1-y^{(i)})\\log(1-h_w(x^{(i)}))]}\\end{eqnarray}$$ 梯度下降法 最大似然估计就是要求得使$ J(θ) $取最大值时的$ θ $，但因此处的$ Cost(h_w(x^{(i)}),y^{(i)}) $添加了一个负号，所以必须用梯度下降法求解最佳参数。但若此处的$ Cost(h_w(x^{(i)}),y^{(i)}) $没有添加负号，则需要用梯度上升法求解最佳参数。 先把$ J(w) $对$ w_j $的一阶偏导求出来，且用$ g $表示。$ g $是梯度向量。 $$\\begin{eqnarray}g_j &amp;=&amp; \\frac{\\partial J(w)}{\\partial w_j}\\\\&amp;=&amp; -\\frac{1}{m}\\sum_{i=1}^{m}(\\frac{y^{(i)}}{h_w(x^{(i)})} h_w(x^{(i)}) (1-h_w(x^{(i)}))(-x_{j}^{(i)}) + (1-y^{(i)})\\frac {1}{1-h_w(x^{(i)})}h_w(x^{(i)})(1-h_w(x^{(i)}))x_j^{(i)}) \\\\&amp;=&amp; -\\frac{1}{m}\\sum_{i=1}^{m}(y^{(i)}-h_w(x^{(i)}))x_{j}^{(i)})\\end{eqnarray}$$ 梯度下降是通过$ J(w) $对$ w $的一阶导数来找下降方向（负梯度），并且以迭代的方式来更新参数，更新方式为 $$\\begin{eqnarray}w^{k+1}_j &amp;=&amp; w^k_j+α(-g_j)\\\\&amp;=&amp;w^k_j+α \\frac{1}{m}\\sum_{i=1}^{m}(y^{(i)}-h_w(x^{(i)}))x_{j}^{(i)}\\label{eq:lr-gd}\\end{eqnarray}$$ $ k $为迭代次数。每次更新参数后，可以通过比较$||J(w^{k+1})−J(w^k)||$或者$ ||w^{k+1}−w^k ||$与某个阈值$ \\epsilon $大小的方式来停止迭代，即比阈值小就停止。 如果采用梯度上升法来推到参数的更新方式，会发现式子与公式$\\eqref{eq:lr-gd}$完全一样，所以采用梯度上升发和梯度下降法是一样的。 随机梯度下降法从上面梯度下降法中的公式$\\eqref{eq:lr-gd}$中可以看到，每次更新回归系数时都需要遍历整个数据集，如果有数十亿样本和成千上万个特征，则梯度下降法的计算复杂度就太高了。随机梯度下降法一次仅用一个样本点来更新回归系数： $$\\begin{equation}w^{k+1}_j = w^k_j+α (y^{(i)}-h_w(x^{(i)}))x_{j}^{(i)}\\end{equation}$$ 梯度下降过程向量化约定训练数据的矩阵形式如下，$ x $的每一行为一条训练样本，而每一列为不同的特称取值： $$\\begin{equation}x=\\left[\\begin{matrix}x^{(1)}\\\\x^{(2)}\\\\\\ldots\\\\x^{(m)}\\end{matrix}\\right]=\\left[\\begin{matrix}x_0^{(1)} &amp; x_1^{(1)} &amp; \\ldots &amp; x_n^{(1)}\\\\x_0^{(2)} &amp; x_1^{(2)} &amp; \\ldots &amp; x_n^{(2)}\\\\\\ldots &amp; \\ldots &amp; \\ldots &amp; \\ldots \\\\x_0^{(m)} &amp; x_1^{(m)} &amp; \\ldots &amp; x_n^{(m)}\\end{matrix}\\right],y=\\left[\\begin{matrix}y^{(1)}\\\\y^{(2)}\\\\\\ldots\\\\y^{(m)}\\end{matrix}\\right]\\end{equation}$$ 约定待求的参数θ的矩阵形式为： $$\\begin{equation}\\theta =\\left[\\begin{matrix}\\theta_1\\\\\\theta_2\\\\\\ldots\\\\\\theta_n\\end{matrix}\\right]\\end{equation}$$ 先求$ x \\cdot \\theta $并记为$ A $： $$\\begin{equation}A=x \\cdot \\theta=\\left[\\begin{matrix}x_0^{(1)} &amp; x_1^{(1)} &amp; \\ldots &amp; x_n^{(1)}\\\\x_0^{(2)} &amp; x_1^{(2)} &amp; \\ldots &amp; x_n^{(2)}\\\\\\ldots &amp; \\ldots &amp; \\ldots &amp; \\ldots \\\\x_0^{(m)} &amp; x_1^{(m)} &amp; \\ldots &amp; x_n^{(m)}\\end{matrix}\\right]\\cdot\\left[\\begin{matrix}\\theta_0\\\\\\theta_1\\\\\\ldots\\\\\\theta_n\\end{matrix}\\right]=\\left[\\begin{matrix}\\theta_0x_0^{(1)} + \\theta_1x_1^{(1)} + \\ldots + \\theta_nx_n^{(1)}\\\\\\theta_0x_0^{(2)} + \\theta_1x_1^{(2)} + \\ldots + \\theta_nx_n^{(2)}\\\\\\ldots \\\\\\theta_0x_0^{(m)} + \\theta_1x_1^{(m)} + \\ldots + \\theta_nx_n^{(m)}\\end{matrix}\\right]\\end{equation}$$ 求$ h_\\theta(x)-y $并记为$ E $： $$\\begin{equation}E=h_\\theta(x)-y=\\left[\\begin{matrix}g(A^{(1)})-y^{(1)}\\\\g(A^{(2)})-y^{(2)}\\\\\\ldots \\\\g(A^{(m)})-y^{(m)}\\end{matrix}\\right]=\\left[\\begin{matrix}e^{(1)}\\\\e^{(2)}\\\\\\ldots\\\\e^{(m)}\\end{matrix}\\right]=g(A)-y\\end{equation}$$ 由上式可知$ h_\\theta(x)-y $可以由$ g(A)-y $一次计算求得。 再来看一下公式$\\eqref{eq:lr-gd}$的$\\theta$更新过程： $$\\begin{eqnarray}\\theta_j &amp;=&amp; \\theta_j + \\alpha \\sum_{i=1}^{m}(-e^{(i)})x_j^{(i)}\\\\&amp;=&amp; \\theta_j-\\alpha\\cdot(x_j^{(1)},x_j^{(2)},\\ldots,x_j^{(m)})\\cdot E\\end{eqnarray}$$ 综合上面的式子有： $$\\begin{equation}\\theta = \\theta - \\alpha\\cdot\\frac{1}{m}\\cdot x^T\\cdot(g(x\\cdot\\theta)-y)\\end{equation}$$ 正则化由于模型的参数个数一般是由人为指定和调节的，所以正则化常常是用来限制模型参数值不要过大，也被称为惩罚项。一般是在目标函数(经验风险)中加上一个正则化项$ \\Phi(w) $即 $$\\begin{equation}J(w) = -\\frac{1}{m}[\\sum_{i=1}^{m}y_ilog h_w (x_i) + (1-y_i)log(1-h_w(x_i))] + \\lambda \\Phi(w)\\label{eq:reg}\\end{equation}$$ 而这个正则化项一般会采用L1范数或者L2范数。其形式分别为$ \\Phi (w)=||x||_1 $和$ \\Phi (w)=||x||_2 $。 首先针对L1范数$ \\Phi (w)=|x| $，当采用梯度下降方式来优化目标函数时，对目标函数进行求导，正则化项导致的梯度变化当$ w_j &gt; 0 $是取1，当$ w_j &lt; 0 $时取-1. 从而导致的参数$w_j$减去了学习率与公式的乘积，因此当$ w_j &gt; 0 $的时候，$ w_j$会减去一个正数，导致$ w_j $减小，而当$ w_j &lt; 0 $的时候，$ w_j$会减去一个负数，导致$ w_j$又变大，因此这个正则项会导致参数$ w_j$取值趋近于0，也就是为什么L1正则能够使权重稀疏，这样参数值就受到控制会趋近于0。L1正则还被称为 Lasso regularization。 然后针对L2范数$\\phi(w) = \\sum_{j=1}^{n}w_j^2$，同样对它求导，得到梯度变化为$\\frac{\\partial \\Phi(w)}{\\partial w_j} = 2w_j$(一般会用$\\frac{\\lambda}{2}$来把这个系数2给消掉)。同样的更新之后使得$ w_j$的值不会变得特别大。在机器学习中也将L2正则称为weight decay，在回归问题中，关于L2正则的回归还被称为Ridge Regression岭回归。weight decay还有一个好处，它使得目标函数变为凸函数，梯度下降法和L-BFGS都能收敛到全局最优解。 需要注意的是，L1正则化会导致参数值变为0，但是L2却只会使得参数值减小，这是因为L1的导数是固定的，参数值每次的改变量是固定的，而L2会由于自己变小改变量也变小。而公式$\\eqref{eq:reg}$中的$\\lambda$也有着很重要的作用，它在权衡拟合能力和泛化能力对整个模型的影响，$\\lambda$越大，对参数值惩罚越大，泛化能力越好。 《机器学习实战》代码梯度上升法： 1234567891011121314def gradAscent(dataMatIn, classLabels): \"\"\"梯度上升法\"\"\" dataMatrix = mat(dataMatIn) labelMat = mat(classLabels).transpose() m, n = shape(dataMatrix) alpha = 0.1 maxCycles = 500 weights = ones((n, 1)) for k in range(maxCycles): a = dataMatrix * weights h = sigmoid(dataMatrix * weights) # 100*3 3*1 error = (labelMat - h) weights = weights + alpha / m * dataMatrix.transpose() * error return weights 随机梯度下降法： 1234567891011121314151617181920212223242526def stocGradAscent0(dataMatrix, classLabels): \"\"\"随机梯度上升法，但是迭代次数不够，且可能存在局部波动现象\"\"\" m, n = shape(dataMatrix) alpha = 0.01 weights = ones(n) for i in range(m): h = sigmoid(sum(dataMatrix[i] * weights)) error = classLabels[i] - h weights = weights + alpha * error * dataMatrix[i] return weightsdef stocGradAscent1(dataMatrix, classLabels, numIter=150): \"\"\"改进的随机梯度上升法\"\"\" m, n = dataMatrix.shape weights = ones(n) for j in range(numIter): dataIndex = range(m) for i in range(m): alpha = 4 / (1.0 + j + i) + 0.01 # alpha在每次迭代时都进行了调整 randIndex = int(random.uniform(0, len(dataIndex))) # 随机选取样本数据 h = sigmoid(sum(dataMatrix[randIndex] * weights)) error = classLabels[randIndex] - h weights = weights + alpha * error * dataMatrix[randIndex] del (dataIndex[randIndex]) return weights 参考文献 【机器学习笔记1】Logistic回归总结【机器学习算法系列之二】浅析Logistic Regression牛顿法与拟牛顿法学习笔记（一）牛顿法 MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: \"AMS\" } } });","raw":null,"content":null,"categories":[{"name":"ML","slug":"ML","permalink":"https://comwork2016.github.io/categories/ML/"}],"tags":[{"name":"ML","slug":"ML","permalink":"https://comwork2016.github.io/tags/ML/"},{"name":"LR","slug":"LR","permalink":"https://comwork2016.github.io/tags/LR/"}]},{"title":"Latex数学公式","slug":"Latex数学公式","date":"2017-04-01T00:42:07.000Z","updated":"2017-04-06T01:45:57.092Z","comments":true,"path":"2017/04/01/Latex数学公式/","link":"","permalink":"https://comwork2016.github.io/2017/04/01/Latex数学公式/","excerpt":"Latex中的常用命令。","text":"Latex中的常用命令。 多行的数学公式1234\\begin&#123;eqnarray*&#125;\\cos 2\\theta &amp; = &amp; \\cos^2 \\theta - \\sin^2 \\theta \\\\&amp; = &amp; 2 \\cos^2 \\theta - 1.\\end&#123;eqnarray*&#125; 其中&amp;是对其点，表示在此对齐。$$\\begin{eqnarray*}\\cos 2\\theta &amp; = &amp; \\cos^2 \\theta - \\sin^2 \\theta \\\\&amp; = &amp; 2 \\cos^2 \\theta - 1.\\end{eqnarray*}$$ 数学公式自动编号在文件中添加一下javascript代码12345&lt;script type=\"text/x-mathjax-config\"&gt;MathJax.Hub.Config(&#123; TeX: &#123; equationNumbers: &#123; autoNumber: \"AMS\" &#125; &#125;&#125;);&lt;/script&gt; 公式的标记和引用使用：\\label{maker}来标记公式，使用\\eqref{maker}来引用公式。$$\\begin{equation}\\cos 2\\theta = \\cos^2 \\theta - \\sin^2 \\theta\\label{eq:test1}\\end{equation}$$如引用公式$\\ref{eq:test1}$ MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: \"AMS\" } } });","raw":null,"content":null,"categories":[{"name":"tools","slug":"tools","permalink":"https://comwork2016.github.io/categories/tools/"}],"tags":[{"name":"math","slug":"math","permalink":"https://comwork2016.github.io/tags/math/"},{"name":"latex","slug":"latex","permalink":"https://comwork2016.github.io/tags/latex/"}]},{"title":"删除已经提交的Ignore file","slug":"删除已经提交的Ignore-file","date":"2017-03-31T10:55:30.000Z","updated":"2017-04-01T11:56:30.616Z","comments":true,"path":"2017/03/31/删除已经提交的Ignore-file/","link":"","permalink":"https://comwork2016.github.io/2017/03/31/删除已经提交的Ignore-file/","excerpt":"","text":"To untrack a single file that has already been added/initialized to your repository, i.e., stop tracking the file but not delete it from your system use: 1git rm --cached filename To untrack every file that is now in your .gitignore: First commit any outstanding code changes, and then, run this command: 1git rm -r --cached . This removes any changed files from the index(staging area), then just run: 1git add . Commit it: 1git commit -m \".gitignore is now working\"","raw":null,"content":null,"categories":[{"name":"git","slug":"git","permalink":"https://comwork2016.github.io/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"https://comwork2016.github.io/tags/git/"},{"name":"ignore","slug":"ignore","permalink":"https://comwork2016.github.io/tags/ignore/"}]},{"title":"用rebase -i 修改提交","slug":"用rebase-i-修改提交","date":"2017-03-31T10:25:26.000Z","updated":"2017-04-01T11:56:30.617Z","comments":true,"path":"2017/03/31/用rebase-i-修改提交/","link":"","permalink":"https://comwork2016.github.io/2017/03/31/用rebase-i-修改提交/","excerpt":"如果commit的message填写错误，可以通过git的rebase来修改提交信息。","text":"如果commit的message填写错误，可以通过git的rebase来修改提交信息。 用rebase -i，首先选择要修改的提交。 1$ git rebase -i HEAD~~ 打开文本编辑器，将看到从HEAD到HEAD~~的提交如下图显示。12345678910111213141516pick 9a54fd4 添加commit的说明pick 0d4a808 添加pull的说明# Rebase 326fc9f..0d4a808 onto d286baa## Commands:# p, pick = use commit# r, reword = use commit, but edit the commit message# e, edit = use commit, but stop for amending# s, squash = use commit, but meld into previous commit# f, fixup = like \"squash\", but discard this commit's log message# x, exec = run command (the rest of the line) using shell## If you remove a line here THAT COMMIT WILL BE LOST.# However, if you remove everything, the rebase will be aborted.# 将第一行的pick改成edit，然后保存并退出。将会显示以下内容，修改过的提交呈现退出状态。 12345678Stopped at d286baa... 添加commit的说明You can amend the commit now, with git commit --amendOnce you are satisfied with your changes, run git rebase --continue 打开sample.txt，适当地修改commit的讲解部分。 1234连猴子都懂的Git命令add 把变更录入到索引中commit 记录索引的状态pull 取得远端数据库的内容 用commit --amend保存修改。 12$ git add sample.txt$ git commit --amend 现在已经commit，但是rebase操作还没结束。若要通知这个提交的操作已经结束，请指定 --continue选项执行rebase。 1$ git rebase --continue 这时，有可能其他提交会发生冲突, 请修改冲突部分后再执行add和rebase –continue。这时不需要提交。如果在中途要停止rebase操作，请在rebase指定–abort选项执行，这样就可以抹去并停止在rebase的操作。 提交的修改完成了。如果要把多个提交修改成edit，下一个要修改的提交会退出，请执行同样的修改。 实际上，在rebase之前的提交会以ORIG_HEAD之名存留。如果rebase之后无法复原到原先的状态，可以用git reset –hard ORIG_HEAD复原到rebase之前的状态。","raw":null,"content":null,"categories":[{"name":"git","slug":"git","permalink":"https://comwork2016.github.io/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"https://comwork2016.github.io/tags/git/"}]},{"title":"windows 删除快捷方式箭头","slug":"windows-删除快捷方式箭头","date":"2017-03-31T10:14:52.000Z","updated":"2017-04-01T11:56:30.616Z","comments":true,"path":"2017/03/31/windows-删除快捷方式箭头/","link":"","permalink":"https://comwork2016.github.io/2017/03/31/windows-删除快捷方式箭头/","excerpt":"windows 删除快捷方式箭头的脚本。","text":"windows 删除快捷方式箭头的脚本。 删除快捷方式的箭头：1234567reg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Icons\" /v 29 /d \"%systemroot%\\system32\\imageres.dll,197\" /t reg_sz /ftaskkill /f /im explorer.exeattrib -s -r -h \"%userprofile%\\AppData\\Local\\iconcache.db\"del \"%userprofile%\\AppData\\Local\\iconcache.db\" /f /qstart explorerpause` 同样，如果想恢复快捷方式小箭头，只需要将文本文件的内容改成以下内容即可：123456reg delete \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Icons\" /v 29 /ftaskkill /f /im explorer.exeattrib -s -r -h \"%userprofile%\\AppData\\Local\\iconcache.db\"del \"%userprofile%\\AppData\\Local\\iconcache.db\" /f /qstart explorerpause 然后再次以管理员身份运行即可。","raw":null,"content":null,"categories":[{"name":"tools","slug":"tools","permalink":"https://comwork2016.github.io/categories/tools/"}],"tags":[{"name":"tools","slug":"tools","permalink":"https://comwork2016.github.io/tags/tools/"},{"name":"windows","slug":"windows","permalink":"https://comwork2016.github.io/tags/windows/"},{"name":"快捷方式","slug":"快捷方式","permalink":"https://comwork2016.github.io/tags/快捷方式/"}]},{"title":"文件名过长，导致无法删除","slug":"文件名过长，导致无法删除","date":"2017-03-31T10:04:58.000Z","updated":"2017-04-01T11:56:30.617Z","comments":true,"path":"2017/03/31/文件名过长，导致无法删除/","link":"","permalink":"https://comwork2016.github.io/2017/03/31/文件名过长，导致无法删除/","excerpt":"文件名过长，导致无法删除的解决方案。","text":"文件名过长，导致无法删除的解决方案。 在桌面上新建“文本文档”（用附件中的“记事本”） 写入下列命令： 12DEL /F /A /Q \\\\?\\%1RD /S /Q \\\\?\\%1 另存为”删除OK.bat” 一定要选另存为！保存类型选“所有文件” 建好后，把要删除的文件或者目录拖放到这个bat文件的图标上就可以删除了。一切OK!","raw":null,"content":null,"categories":[{"name":"tools","slug":"tools","permalink":"https://comwork2016.github.io/categories/tools/"}],"tags":[{"name":"windows","slug":"windows","permalink":"https://comwork2016.github.io/tags/windows/"},{"name":"删除","slug":"删除","permalink":"https://comwork2016.github.io/tags/删除/"}]},{"title":"vi 颜色设置","slug":"vi-颜色设置","date":"2017-03-31T09:18:12.000Z","updated":"2017-04-01T11:56:30.615Z","comments":true,"path":"2017/03/31/vi-颜色设置/","link":"","permalink":"https://comwork2016.github.io/2017/03/31/vi-颜色设置/","excerpt":"编辑~./vimrc文件","text":"编辑~./vimrc文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667set nocompatible \" Use Vim defaults (much better!) set bs=2 \" allow backspacing over everything in insert mode set ai \" always set autoindenting on \"set backup \" keep a backup file set viminfo='20,\\\"50 \" read/write a .viminfo file, don't store more \" than 50 lines of registers set history=50 \" keep 50 lines of command line history set ruler \" show the cursor position all the time syntax on set hlsearch set incsearch set tabstop=4 set autoindent set cindent set confirm set number set expandtab set autoindent set smartindent filetype indent on if v:lang =~ \"utf8\" || v:lang =~ \"UTF-8\" set fileencodings=utf-8,latin1 endif set syn=cpp \" Only do this part when compiled with support for autocommands if has(\"autocmd\") \" In text files, always limit the width of text to 78 characters autocmd BufRead *.txt set tw=78 \" When editing a file, always jump to the last cursor position autocmd BufReadPost * \\ if line(\"'\\\"\") &gt; 0 &amp;&amp; line (\"'\\\"\") &lt;= line(\"&#123;1\") | \\ exe \"normal! g'\\\"\" | \\ endif endif if has(\"cscope\") set csprg=/usr/bin/cscope set csto=0 set cst set nocsverb \" add any database in current directory if filereadable(\"cscope.out\") cs add cscope.out \" else add database pointed to by environment elseif $CSCOPE_DB != \"\" cs add $CSCOPE_DB endif set csverb endif \" Switch syntax highlighting on, when the terminal has colors \" Also switch on highlighting the last used search pattern. syntax on set hlsearch if &amp;term==\"xterm\" set t_Co=8 set t_Sb=m set t_Sf=m endif set tags=tags se cursorline se cursorcolumn hi cursorline cterm=NONE ctermbg=darkred ctermfg=white guibg=darkred guifg=white hi cursorcolumn cterm=NONE ctermbg=darkred ctermfg=white guibg=darkred guifg=white","raw":null,"content":null,"categories":[{"name":"tools","slug":"tools","permalink":"https://comwork2016.github.io/categories/tools/"}],"tags":[{"name":"tools","slug":"tools","permalink":"https://comwork2016.github.io/tags/tools/"},{"name":"配色","slug":"配色","permalink":"https://comwork2016.github.io/tags/配色/"},{"name":"vi","slug":"vi","permalink":"https://comwork2016.github.io/tags/vi/"}]},{"title":"ubuntu终端颜色配置","slug":"ubuntu终端颜色配置","date":"2017-03-31T08:53:20.000Z","updated":"2017-04-01T11:56:30.615Z","comments":true,"path":"2017/03/31/ubuntu终端颜色配置/","link":"","permalink":"https://comwork2016.github.io/2017/03/31/ubuntu终端颜色配置/","excerpt":"打开终端（ctrl+alt+T），会发现里面都是一个颜色，不管是用户名、主机名还是命令都是白色，对开发人员来说带来了不便之处。因为有时候你需要去几十行甚至上百行代码里面去找一些你运行过的命令或你想要的信息。","text":"打开终端（ctrl+alt+T），会发现里面都是一个颜色，不管是用户名、主机名还是命令都是白色，对开发人员来说带来了不便之处。因为有时候你需要去几十行甚至上百行代码里面去找一些你运行过的命令或你想要的信息。 首先在终端里面用 gedit 打开配置文件（~/.bashrc），如： 1$ gedit ~/.bashrc 在最后添加如下代码： 1PS1='\\[\\033[1;31;40m\\]\\u@\\h:\\w\\$\\[\\033[00m\\] ' 重启终端，你就可以看到你的配色了，或者执行 source .bashrc 命令也可以运行新的配色。 配色过程： 前景 背景 颜色 30 40 黑色 31 41 紅色 32 42 绿色 33 43 黄色 34 44 蓝色 35 45 紫红色 36 46 青蓝色 37 47 白色 代码 意义 0 OFF 1 高亮显示 4 underline 5 闪烁 7 反白显示 8 不可见 一个单独的颜色设置:\\033[代码;前景;背景m，如：\\[\\033[1;32;40m\\]表示高亮显示字体为绿色，背景色为黑色。 注意：颜色的设置，放在相应的要设置的前面，如用户名颜色设置：\\[\\033[01;35;40m\\]\\u","raw":null,"content":null,"categories":[{"name":"tools","slug":"tools","permalink":"https://comwork2016.github.io/categories/tools/"}],"tags":[{"name":"tools","slug":"tools","permalink":"https://comwork2016.github.io/tags/tools/"},{"name":"bash","slug":"bash","permalink":"https://comwork2016.github.io/tags/bash/"},{"name":"配色","slug":"配色","permalink":"https://comwork2016.github.io/tags/配色/"}]},{"title":"VC6.0不能停止调试程序的解决方案","slug":"VC6-0不能停止调试程序的解决方案","date":"2017-03-31T08:45:09.000Z","updated":"2017-04-01T11:56:30.615Z","comments":true,"path":"2017/03/31/VC6-0不能停止调试程序的解决方案/","link":"","permalink":"https://comwork2016.github.io/2017/03/31/VC6-0不能停止调试程序的解决方案/","excerpt":"VC6.0在Windows7下调试的时候，再结束调试，程序无法退出。","text":"VC6.0在Windows7下调试的时候，再结束调试，程序无法退出。 问题描述 ：当我击F5开始一个项目的调试时，程序在我设置的断点处停止，这时按下Shift+F5后，VC6.0可以退出调试状态，但是windows系统的任务栏上会留下前面调试时产生的程序。该进程不能被结束，即使我使用任务管理器也不可以终止程序。而且，当修改代码之后，就不能重新编译了。想结束该进程的唯一的办法是关闭VC6.0，并重新开启。 解决方案 ：更新两个dll文件的版本。 在VC6.0安装目录下的 Common/MSDev98/Bin 里有两个dll文件：DM.dll 和 TLLOC.dll。将DM.dll替换成6.0.9782.0版本的或更新，将TLLOC.dll替换成6.00.8168.0版本的或更新。 C语言中文网提供了这两个dll文件的下载地址：http://pan.baidu.com/s/1eQHzLwm 提取密码：sg07","raw":null,"content":null,"categories":[{"name":"tools","slug":"tools","permalink":"https://comwork2016.github.io/categories/tools/"}],"tags":[{"name":"vc6.0","slug":"vc6-0","permalink":"https://comwork2016.github.io/tags/vc6-0/"},{"name":"tools","slug":"tools","permalink":"https://comwork2016.github.io/tags/tools/"}]},{"title":"intellij idea 注册服务器","slug":"intellij-idea-注册服务器","date":"2017-03-31T08:32:32.000Z","updated":"2017-04-01T11:56:30.615Z","comments":true,"path":"2017/03/31/intellij-idea-注册服务器/","link":"","permalink":"https://comwork2016.github.io/2017/03/31/intellij-idea-注册服务器/","excerpt":"","text":"Intellij idea 注册服务器地址 lisense server address: http://www.iteblog.com/idea/key.php 服务器更新地址:http://idea.lanyus.com/","raw":null,"content":null,"categories":[{"name":"tools","slug":"tools","permalink":"https://comwork2016.github.io/categories/tools/"}],"tags":[{"name":"idea","slug":"idea","permalink":"https://comwork2016.github.io/tags/idea/"},{"name":"license","slug":"license","permalink":"https://comwork2016.github.io/tags/license/"}]},{"title":"Python split保留分隔符","slug":"Python-split保留分隔符","date":"2017-03-31T08:21:37.000Z","updated":"2017-04-01T11:56:30.614Z","comments":true,"path":"2017/03/31/Python-split保留分隔符/","link":"","permalink":"https://comwork2016.github.io/2017/03/31/Python-split保留分隔符/","excerpt":"python 文本或句子切割，并保留分隔符","text":"python 文本或句子切割，并保留分隔符 主要思想，利用正则表达式re.split() 分割，同时利用re.findall() 查找分隔符，而后将二者链接即可。 12345678910111213141516171819202122# coding: utf-8import sysreload(sys)sys.setdefaultencoding(\"utf-8\")import redef my_split(str,sep=u\"要求\\d+|岗位\\S+\"): # 分隔符可为多样的正则表达式 wlist = re.split(sep,str) sepword = re.findall(sep,str) sepword.insert(0,\" \") # 开头（或末尾）插入一个空字符串，以保持长度和切割成分相同 wlist = [ x+y for x,y in zip(wlist,sepword) ] # 顺序可根据需求调换 return wlistif __name__ == \"__main__\": inputstr = \"岗位：学生： \\n要求1.必须好好学习。\\n要求2.必须踏实努力。\\n要求3.必须求实上进。\" res = my_split(inputstr) print '\\n'.join(res)","raw":null,"content":null,"categories":[{"name":"python","slug":"python","permalink":"https://comwork2016.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://comwork2016.github.io/tags/python/"},{"name":"split","slug":"split","permalink":"https://comwork2016.github.io/tags/split/"}]},{"title":"Python日志模块","slug":"Python日志模块","date":"2017-03-31T07:26:28.000Z","updated":"2017-04-01T11:56:30.614Z","comments":true,"path":"2017/03/31/Python日志模块/","link":"","permalink":"https://comwork2016.github.io/2017/03/31/Python日志模块/","excerpt":"python的标准库里的日志系统从Python2.3开始支持。只要import logging这个模块即可使用。","text":"python的标准库里的日志系统从Python2.3开始支持。只要import logging这个模块即可使用。 日志级别下表中的日志级别从上往下以此升高。logging只会输出比设定级别高的日志信息。 级别 何时使用 DEBUG 详细信息，典型地调试问题时会感兴趣。 INFO 证明事情按预期工作。 WARNING 表明发生了一些意外，或者不久的将来会发生问题（如‘磁盘满了’）。软件还是在正常工作。 ERROR 由于更严重的问题，软件已不能执行一些功能了。 CRITICAL 严重错误，表明软件已不能继续运行了。 关键概念Logger，Handler，Formatter和Filter是日志模块的几个基本概念，日志模块的工作原理要从这四个基本概念说起。 Logger 即记录器，Logger提供了日志相关功能的调用接口。 Handler 即处理器，将（记录器产生的）日志记录发送至合适的目的地。 Filter 即过滤器，提供了更好的粒度控制，它可以决定输出哪些日志记录。 Formatter 即格式化器，指明了最终输出中日志记录的格式。 LoggerLogger 即“记录器”，Logger对象实例是日志记录功能的载体，如： 1234567891011#!/usr/local/bin/python# -*- coding: utf-8 -*-import logginglogger = logging.getLogger('simple_example')logger.debug('debug message')logger.info('info message')logger.warn('warn message')logger.error('error message')logger.critical('critical message') 值得一提的是，Logger对象从不直接实例化，而是通过模块级的功能logging.getLogger(name)创建Logger实例。调用 logging.getLogger(name) 功能时，如果传入的name参数值相同，则总是返回同一个Logger对象实例的引用。 如果没有显式的进行创建，则默认创建一个root logger，并应用默认的日志级别(WARN)、默认的处理器Handler(StreamHandler，即将日志信息打印输出在标准输出上)，和默认的格式化器Formatter(默认的格式即为第一个简单使用程序中输出的格式)。 HandlerHandler 将日志信息发送到设置的位置，可以通过Logger对象的addHandler()方法为Logger对象添加0个或多个handler。一种日志的典型应用场景为，系统希望将所有的日志信息保存到log文件中，其中日志等级等于或高于ERROR的消息还要在屏幕标准输出上显示，日志等级为CRITICAL的还需要发送邮件通知；这种场景就需要3个独立的handler来实现需求，这三个handler分别与指定的日志等级或日志位置做响应 需要一提的是，为Logger配置的handler不能是Handler基类对象，而是Handler的子类对象，常用的Handler为StreamHandler, FileHandler和NullHandler。 FormatterFormatter 用于设置日志输出的格式，与前两个基本概念不同的是，该类可以直接初始化对象，即 formatter=logging.Formatter(fmt=None, datefmt=None)，创建formatter时，传入分别fmt和datefmt参数来修改日志格式和时间格式，默认的日志格式为%(asctime)s - %(levelname)s - %(message)s，默认的时间格式为%Y-%m-%d %H:%M:%S FilterFilter可用于Logger对象或Handler对象，用于提供比日志等级更加复杂的日志过滤方式。默认的filter只允许在指定logger层级下的日志消息通过过滤。例如，如果把filter设置为filter=logging.Filter(&#39;A.B&#39;)，则‘A.B’, ‘A.B.C’, ‘A.B.C.D’, ‘A.B.D’ 产生的日志信息可以通过过滤，但&#39;A.BB&#39;, &#39;B.A.B&#39;均不行。如果以空字符串初始化filter，则所有的日志消息都可以通过过滤。 Filter在日志功能配置中是非必须的，只在对日志消息过滤需求比较复杂时配置使用即可。 使用日志模块如果只需要在控制台输出日志信息，可以用如下格式： 1234import logginglogging.basicConfig(level=logging.DEBUG,format='%(levelname)s: %(asctime)s - %(filename)s:%(lineno)s - %(message)s')logging.info('info logging') 日志也可以同时在控制台和文件中输出，例如如下： 12345678910111213141516171819202122232425import logging# 创建一个loggerlogger = logging.getLogger('mylogger')logger.setLevel(logging.DEBUG)# 创建一个handler，用于写入日志文件fh = logging.FileHandler('test.log')fh.setLevel(logging.DEBUG)# 再创建一个handler，用于输出到控制台ch = logging.StreamHandler()ch.setLevel(logging.DEBUG)# 定义handler的输出格式formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')fh.setFormatter(formatter)ch.setFormatter(formatter)# 给logger添加handlerlogger.addHandler(fh)logger.addHandler(ch)# 记录一条日志logger.info('foorbar')","raw":null,"content":null,"categories":[{"name":"python","slug":"python","permalink":"https://comwork2016.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://comwork2016.github.io/tags/python/"},{"name":"日志","slug":"日志","permalink":"https://comwork2016.github.io/tags/日志/"}]},{"title":"搭建Hexo博客","slug":"搭建Hexo博客","date":"2017-03-31T02:45:23.000Z","updated":"2017-04-01T11:56:30.616Z","comments":true,"path":"2017/03/31/搭建Hexo博客/","link":"","permalink":"https://comwork2016.github.io/2017/03/31/搭建Hexo博客/","excerpt":"本文主要记录Windows系统下搭建Hexo博客，以防遗忘！","text":"本文主要记录Windows系统下搭建Hexo博客，以防遗忘！ 准备你需要准备好以下软件： Node.js Git 安装Hexo在自己认为合适的地方创建一个文件夹，然后在文件夹空白处按住Shift+鼠标右键，然后点击在此处打开命令行窗口。（同样要记住啦，下文中会使用在当前目录打开命令行来代指上述的操作） 在输入以下命令安装Hexo： 12345$ npm install hexo-cli -g$ hexo init$ npm install$ hexo g # 或者hexo generate$ hexo s # 或者hexo server，可以在http://localhost:4000/ 查看 这里有必要提下Hexo常用的几个命令： 12345$ hexo generate (hexo g) 生成静态文件，会在当前目录下生成一个新的叫做public的文件夹$ hexo server (hexo s) 启动本地web服务，用于博客的预览$ hexo deploy (hexo d) 部署播客到远端（比如github, heroku等平台）$ hexo new \"postName\" #新建文章$ hexo new page \"pageName\" #新建页面 常用简写1234$ hexo n == hexo new$ hexo g == hexo generate$ hexo s == hexo server$ hexo d == hexo deploy 在浏览器中打开http://localhost:4000/，你将会看到： 到目前为止，Hexo在本地的配置已经全都结束了。 修改全局配置文件具体可以参考Hexo官方文档 您可以在 _config.yml 中修改大部份的配置。 例如配置文件如下： 更换主题可以在此处寻找自己喜欢的主题下载所有的主题文件，保存到Hexo目录下的themes文件夹下。然后在_config.yml文件中修改： 1234# Extensions## Plugins: http://hexo.io/plugins/## Themes: http://hexo.io/themes/theme: landscape //themes文件夹中对应文件夹的名称 然后先执行hexo clean，然后重新hexo g，并且hexo d，很快就能看到新主题的效果了~ 创建代码库创建GitHub Pages的Repository name必须使用yourname.github.io，如图所示： 开启GitHub Pages功能开启GitHub Pages之前，必须有master分支存在。点击界面右侧的Settings，你将会打开这个库的setting页面，将GitHub Pages中的Source选中master： Github将会自动替你创建出一个gh-pages的页面。如果你的配置没有问题，yourname.github.io这个网址就可以正常访问了~如果yourname.github.io已经可以正常访问了，那么Github一侧的配置已经全部结束了。 部署Hexo到Github Pages这一步恐怕是最关键的一步了，让我们把在本地web环境下预览到的博客部署到github上，然后就可以直接通过http://yourname.github.io/访问了。 首先需要明白所谓部署到github的原理。 之前步骤中在Github上创建的那个特别的repo（yourname.github.io）一个最大的特点就是其master中的html静态文件，可以通过链接http://yourname.github.io/来直接访问。 Hexo -g会生成一个静态网站（第一次会生成一个public目录），这个静态文件可以直接访问。 需要将hexo生成的静态网站，提交(git commit)到github上。 明白了原理，怎么做自然就清晰了。 使用hexo deploy部署hexo deploy可以部署到很多平台，具体可以参考这个链接. 如果部署到github，需要在配置文件_config.xml中作如下修改： 1234deploy: type: git repo: git@github.com:comwork2016/comwork2016.github.io.git branch: master 然后在命令行中执行 1hexo d 即可完成部署。 踩坑提醒 注意需要提前安装一个扩展： 1$ npm install hexo-deployer-git --save 使用git命令行部署（optional）不幸的是，上述命令虽然简单方便，但是偶尔会有莫名其妙的问题出现，因此，我们也可以追本溯源，使用git命令来完成部署的工作。 clone github repo 12$ cd /blog$ git clone git@github.com:comwork2016/comwork2016.github.io.git .deploy/comwork2016.github.io 将我们之前创建的repo克隆到本地，新建一个目录叫做.deploy用于存放克隆的代码。 创建一个deploy脚本文件123456hexo generatecp -R public/* .deploy/comwork2016.github.iocd .deploy/comwork2016.github.iogit add .git commit -m updategit push origin master 简单解释一下，hexo generate生成public文件夹下的新内容，username.github.io的git目录下，然后使用git commit命令提交代码到username.github.io这个repo的master branch上。 需要部署的时候，执行这段脚本就可以了（比如可以将其保存为deploy.sh）。执行过程中可能需要让你输入Github账户的用户名及密码，按照提示操作即可。 更换域名首先，需要注册一个域名。在你的域名注册提供商那里配置DNS解析，获取GitHub的IP地址，进入source目录下，添加CNAME文件 12345$ cd source/$ touch CNAME$ vim CNAME # 输入你的域名$ git add CNAME$ git commit -m \"add CNAME\" 添加404公益页面GitHub Pages有提供制作404页面的指引：Custom 404 Pages。 直接在根目录下创建自己的404.html或者404.md就可以。但是自定义404页面仅对绑定顶级域名的项目才起作用，GitHub默认分配的二级域名是不起作用的，使用hexo server在本机调试也是不起作用的。 推荐使用腾讯公益404。 添加about页面1$ hexo new page \"about\" 之后在/source/about/index.md目录下会生成一个index.md文件，打开输入个人信息即可，如果想要添加版权信息，可以在文件末尾添加： 添加Fork me on Github获取代码，选择你喜欢的代码添加到/themes/yilia/layout/layout.ejs的末尾即可，注意要将代码里的you改成你的Github账号名。 添加支付宝捐赠按钮及二维码支付 支付宝捐赠按钮 在/themes/yilia/layout_widget目录下新建一个zhifubao.ejs文件，内容如下1234567891011&lt;p class=\"asidetitle\"&gt;打赏他&lt;/p&gt;&lt;div&gt;&lt;form action=\"https://shenghuo.alipay.com/send/payment/fill.htm\" method=\"POST\" target=\"_blank\" accept-charset=\"GBK\"&gt; &lt;br/&gt; &lt;input name=\"optEmail\" type=\"hidden\" value=\"your 支付宝账号\" /&gt; &lt;input name=\"payAmount\" type=\"hidden\" value=\"默认捐赠金额(元)\" /&gt; &lt;input id=\"title\" name=\"title\" type=\"hidden\" value=\"博主，打赏你的！\" /&gt; &lt;input name=\"memo\" type=\"hidden\" value=\"你Y加油，继续写博客！\" /&gt; &lt;input name=\"pay\" type=\"image\" value=\"转账\" src=\"http://7xig3q.com1.z0.glb.clouddn.com/alipay-donate-website.png\" /&gt;&lt;/form&gt;&lt;/div&gt; 添加完该文件之后，要在/themes/yilia/_config.ym文件中启用，如下所示，添加zhifubao1234567widgets:- category- tag- links- tagcloud- zhifubao- rss 二维码捐赠 首先需要到这里获取你的支付宝账户的二维码图片，支付宝提供了自定义功能，可以添加自定义文字。 我的二维码扫描捐赠添加在about页面，当然你也可以添加到其它页面，在\\source\\about下有index.md，打开，在适当位置添加12345&lt;center&gt;欢迎您捐赠本站，您的支持是我最大的动力！![][http://7xsxyo.com1.z0.glb.clouddn.com/2016/04/15/FoJ1F6Ht0CNaYuCdE2l52F-Fk9Vk202.png]&lt;/center&gt;&lt;br/&gt; 可以让图片居中显示，注意将图片链接地址换成你的即可。 本文原始链接：手把手教你使用Hexo + Github Pages搭建个人独立博客作者：令狐葱","raw":null,"content":null,"categories":[{"name":"tools","slug":"tools","permalink":"https://comwork2016.github.io/categories/tools/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://comwork2016.github.io/tags/hexo/"},{"name":"blog","slug":"blog","permalink":"https://comwork2016.github.io/tags/blog/"}]}]}